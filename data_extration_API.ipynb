{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def newsupdate_api(url):\n",
    "\n",
    "        import requests\n",
    "        import pandas as pd\n",
    "        import tabulate\n",
    "\n",
    "        query_params = {\n",
    "            'apiKey': 'e06b032123404c8b84d51bc464ef477b',\n",
    "            'q': 'publishing',\n",
    "            'language':'en',\n",
    "            'limit':100, \n",
    "            'sortBy': 'Recent',\n",
    "            'domains': 'foxnews.com,thestreet.com,NYTimes.com,forbes.com,indiewire.com,variety.com,nbcnews.com,cbsnews.com,usatoday.com,ctvnews.ca,msnbc.com,espn.com,cbcnews.ca,globalnews.ca,cnn.com,tsnnews.ca,ctvnews.ca'\n",
    "                        }\n",
    "\n",
    "        header ={'content-type': 'application/json' }\n",
    " # List variable to store individual news details\n",
    "        source= []\n",
    "        content = []\n",
    "        title=[]\n",
    "        publishedAt=[]\n",
    " # dictionary variable to store all the news details\n",
    "        article_retrieved ={}\n",
    "        try:\n",
    "                response = requests.get(url, params=query_params,headers=header)\n",
    "                if response.status_code == 200:\n",
    "                        open_news_api= response.json()\n",
    "                        article = open_news_api[\"articles\"]\n",
    "                    \n",
    "# Extract details for each article and add to the list\n",
    "                        \n",
    "                        for ar in article:\n",
    "                            source.append(ar['source'])\n",
    "                            content.append(ar['content'])\n",
    "                            title.append(ar['title'])\n",
    "                            publishedAt.append(ar['publishedAt'])\n",
    "                            article_retrieved={'source':source,'content':content,'headline':title,\n",
    "                                                'date_published':publishedAt}\n",
    "                else:\n",
    "                    print('error from response')\n",
    "\n",
    "        except Exception as error:\n",
    "                    print(f'error:{error}')\n",
    "\n",
    "# Create a DataFrame to print all the articles retrieved and save to CSV\n",
    "        try:\n",
    "            if article_retrieved:\n",
    "                articles_df = pd.DataFrame(article_retrieved)\n",
    "                print(f'Articles Retrieved\\n{tabulate.tabulate(articles_df.set_index(\"source\"),headers=articles_df.columns.tolist(),tablefmt='heavy_grid')}')\n",
    "    \n",
    " # Save the DataFrame to a CSV file\n",
    "                output_file = 'news_articles.csv'\n",
    "                articles_df.to_csv(output_file, index=False)\n",
    "                print(f\"Saved {len(articles_df)} articles to {output_file}\")\n",
    "            else:\n",
    "             print(\"No articles retrieved.\")\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles Retrieved\n",
      "                                      source  \\\n",
      "0               {'id': 'cnn', 'name': 'CNN'}   \n",
      "1             {'id': None, 'name': 'Forbes'}   \n",
      "2             {'id': None, 'name': 'Forbes'}   \n",
      "3             {'id': None, 'name': 'Forbes'}   \n",
      "4             {'id': None, 'name': 'Forbes'}   \n",
      "..                                       ...   \n",
      "95            {'id': None, 'name': 'Forbes'}   \n",
      "96            {'id': None, 'name': 'Forbes'}   \n",
      "97  {'id': 'usa-today', 'name': 'USA Today'}   \n",
      "98    {'id': 'nbc-news', 'name': 'NBC News'}   \n",
      "99            {'id': None, 'name': 'Forbes'}   \n",
      "\n",
      "                                              content  \\\n",
      "0   A Luckin Coffee location China. Monday marks t...   \n",
      "1   Alexandra Elbakyan in Sochi 2021\\r\\nBy Alexand...   \n",
      "2   TikTok\\r\\nGone are the days of focus groups an...   \n",
      "3   getty\\r\\nHeres a jaw-dropping statistic: 45 Su...   \n",
      "4   Is your company's thought-leadership strategy ...   \n",
      "..                                                ...   \n",
      "95  Former Olympic diver Cassidy Krug shares tips ...   \n",
      "96  Enabling your subject-matter experts to find a...   \n",
      "97  Jannik Sinner is -- as of publishing this -- t...   \n",
      "98  DALLAS Southern Baptist delegates at their nat...   \n",
      "99  Julie Wainwright and The RealReal team.\\r\\nCou...   \n",
      "\n",
      "                                             headline        date_published  \n",
      "0   Watch out, Starbucks: China’s biggest coffee c...  2025-06-30T11:09:42Z  \n",
      "1   Science’s Pirate Queen Gets A Memecoin: Sci-Hu...  2025-06-30T09:15:39Z  \n",
      "2   TikTok Transforms Publishing: BookTok's Influe...  2025-06-17T15:03:21Z  \n",
      "3   How Women Are Turning Substack Newsletters Int...  2025-07-01T11:00:00Z  \n",
      "4   Random Acts Of Thought Leadership: Why Strateg...  2025-06-29T14:18:26Z  \n",
      "..                                                ...                   ...  \n",
      "95  How Olympic Diver Cassidy Krug Learned To Let ...  2025-06-28T21:29:46Z  \n",
      "96  How A Corporate Influencer Program Can Feed Yo...  2025-06-28T13:21:19Z  \n",
      "97  Is Jannik Sinner single again after Anna Kalin...  2025-06-08T12:25:10Z  \n",
      "98  Southern Baptist delegates at national meeting...  2025-06-11T12:15:09Z  \n",
      "99  Time To Get Real; Julie Wainwright On Rocking ...  2025-06-10T16:30:58Z  \n",
      "\n",
      "[100 rows x 4 columns]\n",
      "Saved 100 articles to news_articles.csv\n"
     ]
    }
   ],
   "source": [
    "newsupdate_api(\"https://newsapi.org/v2/everything\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
